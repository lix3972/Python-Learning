## torch.nn.CrossEntropyLoss()用于分类的loss  
https://pytorch.org/docs/stable/nn.html?highlight=torch%20nn%20crossentropyloss#torch.nn.CrossEntropyLoss  

    loss = nn.CrossEntropyLoss()  
    input = torch.randn(3, 5, requires_grad=True)  
    target = torch.empty(3, dtype=torch.long).random_(5)  
    output = loss(input, target)  
    output.backward()  
### 注意：
#### 1、 input的shape为 (batch_size, num_class) 2个维度     
num_class表示分类数目，例如cifa10有10个分类：    
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog','horse', 'ship', 'truck')  
那么num_class=10  
#### 2、 target的shape为(batch_size)  1个维度   
target为目标在分类中的索引，序号从0开始。例如：label='plant',则target=0;label='truck',则target=9  
target数据类型为torch.long或torch.int64  
#### 3、用Adam与SGD优化，差别很大
用VGG16对CelebA数据集中有、无眼镜进行分类，同样的程序，用SGD优化，准确率达到99%以上。    
但是用Adam优化，准确率只在50%上下浮动。随着训练次数的增加，并没有改善。  
